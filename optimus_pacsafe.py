import os
import json
import time
import base64
import bcrypt
import requests
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta, timezone
import logging

# ==========================================
# [ì„¤ì •] Optimus Daily + Review Analysis + Statistics + Në°°ì†¡í˜„í™©
# ==========================================
NAVER_CLIENT_ID = os.environ.get("OP_ID_PACSAFE")
NAVER_CLIENT_SECRET = os.environ.get("OP_PW_PACSAFE")
SPREADSHEET_ID = os.environ.get("SHEET_ID_PACSAFE")

PREFIX = "íŒ©ì„¸ì´í”„"
# GCP_SA_KEY í™˜ê²½ë³€ìˆ˜ì—ì„œ JSON ë¡œë“œ
KST = timezone(timedelta(hours=9))

DAYS_RANGE_ARCHIVE = 90

# ğŸ†• ë¦¬ë·° ë¶„ì„ ì„¤ì •
REVIEW_SHEET_NAME = "íŒ©ì„¸ì´í”„ë„¤ì´ë²„ë¦¬ë·°"
REVIEW_ORDER_ID_COL = 22  # Wì—´
REVIEW_TYPE_COL = 2       # Cì—´
REVIEW_PHOTO_COL = 4      # Eì—´
TARGET_COL_INDEX = 26     # AAì—´: ë¦¬ë·°ìœ í˜• ê²°ê³¼
TARGET_HEADER_NAME = "ë¦¬ë·°ìœ í˜•"

TAB_NAME_COST = f"{PREFIX}_ìƒí’ˆì›ê°€"
TAB_NAME_DISPATCH = f"{PREFIX}_ë°°ì†¡ì¤€ë¹„"
TAB_NAME_STATS = "í†µê³„ì‹œíŠ¸_ì •ì‚°ê¸°ë°˜"
TAB_NAME_NDELIVERY_MASTER = f"{PREFIX}_Në°°ì†¡ë§ˆìŠ¤í„°"

# ë¡œê¹…
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('optimus_daily.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

print(f"ğŸ—“ï¸ ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: ìµœê·¼ {DAYS_RANGE_ARCHIVE}ì¼ ìŠ¤ìº” (ë°ì¼ë¦¬ ëª¨ë“œ)")
print(f"ğŸ” ë¦¬ë·°ì •ë°€ë¶„ì„ ëª¨ë“œ: í™œì„±í™”")
print(f"ğŸ“Š í†µê³„ìë™ìƒì„± ëª¨ë“œ: í™œì„±í™”")
print(f"ğŸ“¦ Në°°ì†¡í˜„í™© ëª¨ë“œ: í™œì„±í™”")

# ==========================================
# 1. ì¸ì¦ ë° êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
# ==========================================
def get_naver_token():
    logger.info("ğŸ”‘ [ì¸ì¦] ë„¤ì´ë²„ í† í° ë°œê¸‰ ì¤‘...")
    try:
        timestamp = str(int((time.time() - 3) * 1000))
        pwd = f"{NAVER_CLIENT_ID}_{timestamp}"
        hashed = bcrypt.hashpw(pwd.encode("utf-8"), NAVER_CLIENT_SECRET.encode("utf-8"))
        client_secret_sign = base64.b64encode(hashed).decode("utf-8")
        url = "https://api.commerce.naver.com/external/v1/oauth2/token"
        data = {
            "client_id": NAVER_CLIENT_ID,
            "timestamp": timestamp,
            "grant_type": "client_credentials",
            "client_secret_sign": client_secret_sign,
            "type": "SELF",
        }
        res = requests.post(url, data=data)
        if res.status_code != 200:
            logger.error("âŒ í† í° ë°œê¸‰ ì‹¤íŒ¨")
            return None
        logger.info("   âœ… í† í° ë°œê¸‰ ì„±ê³µ")
        return res.json().get("access_token")
    except Exception as e:
        logger.error(f"âŒ í† í° ë°œê¸‰ ì˜¤ë¥˜: {e}")
        return None


def get_or_create_worksheet(tab_name):
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(os.environ.get("GCP_SA_KEY")), scope)
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(SPREADSHEET_ID)
        try:
            return sh.worksheet(tab_name)
        except:
            logger.info(f"   ğŸ†• ì‹ ê·œ ì‹œíŠ¸ ìƒì„±: {tab_name}")
            return sh.add_worksheet(title=tab_name, rows="200", cols="20")
    except Exception as e:
        logger.error(f"âŒ ì‹œíŠ¸ ì—°ê²° ì˜¤ë¥˜: {e}")
        return None


def get_safe_product_id(p):
    pid = p.get("productId") or p.get("productClassId") or p.get("productOrderId")
    return str(pid) if pid else ""


# ==========================================
# 2. ë°ì´í„° ë²ˆì—­ ë° ìœ í‹¸ë¦¬í‹°
# ==========================================
def translate_status(status_code):
    if not status_code:
        return ""
    code = str(status_code).upper().strip()
    mapping = {
        "PAYMENT_WAITING": "ì…ê¸ˆëŒ€ê¸°",
        "PAYED": "ê²°ì œì™„ë£Œ",
        "PAYMENT_COMPLETED": "ê²°ì œì™„ë£Œ",
        "PRODUCT_PREPARATION": "ë°°ì†¡ì¤€ë¹„",
        "DISPATCHED": "ë°œì†¡ì²˜ë¦¬",
        "DELIVERY": "ë°°ì†¡ì¤‘",
        "DELIVERING": "ë°°ì†¡ì¤‘",
        "DELIVERED": "ë°°ì†¡ì™„ë£Œ",
        "DELIVERY_COMPLETED": "ë°°ì†¡ì™„ë£Œ",
        "PURCHASE_DECIDED": "êµ¬ë§¤í™•ì •",
        "CANCEL": "ì·¨ì†Œ",
        "CANCELED": "ì·¨ì†Œì™„ë£Œ",
        "CANCEL_DONE": "ì·¨ì†Œì™„ë£Œ",
        "ADMIN_CANCEL": "ê´€ë¦¬ìì§ê¶Œì·¨ì†Œ",
        "ADMIN_CANCELED": "ê´€ë¦¬ìì§ê¶Œì·¨ì†Œ",
        "RETURN": "ë°˜í’ˆ",
        "RETURNED": "ë°˜í’ˆì™„ë£Œ",
        "EXCHANGE": "êµí™˜",
        "EXCHANGED": "êµí™˜ì™„ë£Œ",
        "RETURN_REQUEST": "ë°˜í’ˆìš”ì²­",
        "COLLECTING": "ìˆ˜ê±°ì¤‘",
        "COLLECT_DONE": "ìˆ˜ê±°ì™„ë£Œ",
        "RETURN_DONE": "ë°˜í’ˆì™„ë£Œ",
        "RETURN_REJECT": "ë°˜í’ˆê±°ë¶€",
        "EXCHANGE_REQUEST": "êµí™˜ìš”ì²­",
        "EXCHANGE_DONE": "êµí™˜ì™„ë£Œ",
        "EXCHANGE_REDELIVERING": "êµí™˜ì¬ë°°ì†¡",
        "HYUNDAI": "ë¡¯ë°íƒë°°",
    }
    return mapping.get(code, code)


def translate_courier(code):
    if not code:
        return ""
    c_code = str(code).upper().replace(" ", "").strip()
    mapping = {
        "CJGLS": "CJëŒ€í•œí†µìš´",
        "KOREX": "CJëŒ€í•œí†µìš´",
        "HANJIN": "í•œì§„íƒë°°",
        "POST": "ìš°ì²´êµ­íƒë°°",
        "LOGEN": "ë¡œì  íƒë°°",
        "LOTTE": "ë¡¯ë°íƒë°°",
        "HYUNDAI": "ë¡¯ë°íƒë°°",
        "KDEXP": "ê²½ë™íƒë°°",
        "DAESIN": "ëŒ€ì‹ íƒë°°",
    }
    return mapping.get(c_code, code)


def translate_inflow_path(inflow_path, inflow_path_add=""):
    if not inflow_path:
        return ""
    
    path = str(inflow_path).strip()
    path_upper = path.upper()
    
    if path_upper in ["NULL", "UNDEFINED", "NONE", ""]:
        return ""
    
    path_add = str(inflow_path_add).strip() if inflow_path_add else ""
    if path_add.upper() in ["NULL", "UNDEFINED", "NONE", "-"]:
        path_add = ""
    
    exact_mapping = {
        "SHOPPING_SEARCH_AD": "ì‡¼í•‘ê²€ìƒ‰ê´‘ê³ ",
        "SEARCH_AD": "ì‡¼í•‘ê²€ìƒ‰ê´‘ê³ ",
        "BRAND_SEARCH": "ë¸Œëœë“œê²€ìƒ‰ê´‘ê³ ",
        "DISPLAY_AD": "ë””ìŠ¤í”Œë ˆì´ê´‘ê³ ",
        "GFA": "ì„±ê³¼í˜•ë””ìŠ¤í”Œë ˆì´",
        "ADVBOOST": "ADVoost",
        "ADVOOST": "ADVoost",
        "NAVER_SHOPPING": "ë„¤ì´ë²„ì‡¼í•‘",
        "PRICE_COMPARISON": "ê°€ê²©ë¹„êµ",
        "CATALOG": "ì¹´íƒˆë¡œê·¸",
        "NAVER_SEARCH": "ë„¤ì´ë²„ê²€ìƒ‰",
        "NAVER_SERVICE": "ë„¤ì´ë²„ì„œë¹„ìŠ¤",
        "SMARTSTORE": "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´",
        "STORE_HOME": "ìŠ¤í† ì–´í™ˆ",
        "STORE_SEARCH": "ìŠ¤í† ì–´ê²€ìƒ‰",
        "NPLUS_STORE": "N+ìŠ¤í† ì–´ì•±",
        "DIRECT": "ì§ì ‘ìœ ì…",
        "EXTERNAL": "ì™¸ë¶€ìœ ì…",
        "SNS": "SNS",
        "KAKAO": "ì¹´ì¹´ì˜¤",
        "INSTAGRAM": "ì¸ìŠ¤íƒ€ê·¸ë¨",
    }
    
    if path_upper in exact_mapping:
        result = exact_mapping[path_upper]
        if path_add:
            return f"{result}({path_add})"
        return result
    
    for key in sorted(exact_mapping.keys(), key=len, reverse=True):
        if key in path_upper:
            result = exact_mapping[key]
            if path_add:
                return f"{result}({path_add})"
            return result
    
    if path_add:
        return f"{path}({path_add})"
    return path


def get_tracking_url(courier, tracking_no):
    if not courier or not tracking_no:
        return ""
    clean_no = str(tracking_no).replace("-", "").strip()
    if "CJ" in courier:
        return f"https://trace.cjlogistics.com/next/tracking.html?wblNo={clean_no}"
    elif "í•œì§„" in courier:
        return f"https://www.hanjin.com/kor/CMS/DeliveryMgr/WaybillResult.do?mCode=MN038&wblnum={clean_no}&schLang=KR&wblnumText="
    elif "ìš°ì²´êµ­" in courier:
        return f"https://service.epost.go.kr/trace.RetrieveDomRgiTraceList.comm?sid1={clean_no}"
    elif "ë¡œì  " in courier:
        return f"https://www.ilogen.com/web/personal/trace/{clean_no}"
    elif "ë¡¯ë°" in courier:
        return f"https://www.lotteglogis.com/home/reservation/tracking/linkView?InvNo={clean_no}"
    return f"https://search.naver.com/search.naver?query={courier}+{clean_no}"


def fmt(n):
    try:
        return f"{int(n):,}" if n else "0"
    except:
        return "0"


# ==========================================
# 3. ë¦¬ë·° ì •ë°€ ë¶„ì„ í•¨ìˆ˜
# ==========================================
def clean_order_id(order_id):
    if not order_id:
        return ""
    cleaned = (
        str(order_id)
        .strip()
        .replace("'", "")
        .replace('"', "")
        .replace("\n", "")
    )
    return cleaned


def analyze_review_type(review_type, photo_attached):
    r_type = str(review_type).strip()
    r_photo = str(photo_attached).strip()
    has_photo = bool(r_photo and r_photo != "-" and r_photo != "ì—†ìŒ")

    if "í•œë‹¬" in r_type:
        return "í•œë‹¬í¬í† " if has_photo else "í•œë‹¬í…ìŠ¤íŠ¸"
    else:
        return "ì¼ë°˜í¬í† " if has_photo else "ì¼ë°˜í…ìŠ¤íŠ¸"


def load_review_database_advanced():
    logger.info("ğŸ“’ [ë¦¬ë·°DB] ì •ë°€ë¶„ì„ ëª¨ë“œ: ë¦¬ë·° ì‹œíŠ¸ ì¡°íšŒ ì¤‘...")
    ws = get_or_create_worksheet(REVIEW_SHEET_NAME)
    if not ws:
        logger.warning("   âš ï¸  ë¦¬ë·° ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    try:
        rows = ws.get_all_values()
        review_db = {}
        skipped = 0
        MAX_COL = max(REVIEW_ORDER_ID_COL, REVIEW_TYPE_COL, REVIEW_PHOTO_COL)

        for i, row in enumerate(rows[1:], start=2):
            if len(row) <= MAX_COL:
                skipped += 1
                continue

            order_id = clean_order_id(row[REVIEW_ORDER_ID_COL])

            if not order_id:
                skipped += 1
                continue

            review_type = row[REVIEW_TYPE_COL]
            photo_attached = row[REVIEW_PHOTO_COL]
            label = analyze_review_type(review_type, photo_attached)

            if order_id in review_db:
                review_db[order_id].add(label)
            else:
                review_db[order_id] = {label}

        logger.info(f"   âœ… {len(review_db)}ê±´ ë¡œë“œ ì™„ë£Œ (ìŠ¤í‚µ: {skipped}ê±´)")
        return review_db

    except Exception as e:
        logger.error(f"   âŒ ë¦¬ë·°DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


# ==========================================
# 4. ë„¤ì´ë²„ API ë°ì´í„° ì¡°íšŒ
# ==========================================
def fetch_target_orders_for_dispatch(token):
    logger.info("ğŸ”¥ [ë°°ì†¡ì¤€ë¹„] ì‹ ê·œ ë°ì´í„° ìŠ¤ìº” ì¤‘...")
    headers = {"Authorization": f"Bearer {token}"}
    now = datetime.now(KST)
    from_dt = now - timedelta(days=1)
    last_changed_from = from_dt.isoformat(timespec="milliseconds")
    try:
        res = requests.get(
            "https://api.commerce.naver.com/external/v1/pay-order/seller/product-orders/last-changed-statuses",
            headers=headers,
            params={"lastChangedFrom": last_changed_from, "limitCount": 300},
        )
        data = res.json().get("data", {})
        chunk_ids = list(
            set(
                ch.get("productOrderId")
                for ch in data.get("lastChangeStatuses", [])
                if ch.get("productOrderId")
            )
        )
        final_orders = []
        if chunk_ids:
            get_details(token, chunk_ids, final_orders)
        return final_orders
    except Exception as e:
        logger.error(f"âŒ ë°°ì†¡ì¤€ë¹„ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def fetch_recent_changes_for_archive(token):
    logger.info(f"ğŸ“‰ [ì¥ë¶€ì •ë¦¬] ìµœê·¼ {DAYS_RANGE_ARCHIVE}ì¼ ë°ì´í„° ìŠ¤ìº” ì¤‘...")
    now_kst = datetime.now(KST)
    final_orders = []
    seen_ids = set()

    for i in range(DAYS_RANGE_ARCHIVE, -1, -1):
        try:
            target_date = now_kst - timedelta(days=i)
            start_utc = target_date.astimezone(timezone.utc)
            last_changed_from = start_utc.strftime("%Y-%m-%dT%H:%M:%S.000Z")

            if i % 3 == 0:
                logger.info(f"   ... {target_date.strftime('%Y-%m-%d')} ë°ì´í„° ì¡°íšŒ ì¤‘")

            res = requests.get(
                "https://api.commerce.naver.com/external/v1/pay-order/seller/product-orders/last-changed-statuses",
                headers={"Authorization": f"Bearer {token}"},
                params={"lastChangedFrom": last_changed_from},
            )
            if res.status_code == 200:
                chunk_ids = []
                for item in res.json().get("data", {}).get("lastChangeStatuses", []):
                    pid = item.get("productOrderId")
                    if pid and pid not in seen_ids:
                        chunk_ids.append(pid)
                        seen_ids.add(pid)
                if chunk_ids:
                    get_details(token, chunk_ids, final_orders)

            time.sleep(0.05)

        except Exception as e:
            logger.warning(f"âš ï¸  ë‚ ì§œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            continue

    logger.info(f"   âœ… ì´ {len(final_orders)}ê±´ì˜ ì£¼ë¬¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    return final_orders


def get_details(token, chunk_ids, final_list):
    headers = {"Authorization": f"Bearer {token}"}
    for i in range(0, len(chunk_ids), 50):
        try:
            res = requests.post(
                "https://api.commerce.naver.com/external/v1/pay-order/seller/product-orders/query",
                headers=headers,
                json={"productOrderIds": chunk_ids[i : i + 50]},
            )
            if res.status_code == 200:
                data = res.json().get("data", [])
                if isinstance(data, list):
                    final_list.extend(data)
                elif isinstance(data, dict):
                    final_list.extend(data.get("contents", []))
            time.sleep(0.05)
        except Exception as e:
            logger.warning(f"âš ï¸  ìƒì„¸ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")


# ==========================================
# 5. ë°°ì†¡ì¤€ë¹„ ì‹œíŠ¸ ì—…ë°ì´íŠ¸
# ==========================================
def auto_fill_dispatch_sheet(token, orders):
    logger.info("ğŸšš [ë°°ì†¡ì¤€ë¹„] ëª©ë¡ ì¬ê²€ì¦ ë° ë™ê¸°í™” ì¤‘...")
    ws = get_or_create_worksheet(TAB_NAME_DISPATCH)
    if not ws:
        return

    try:
        all_rows = ws.get_all_values()
    except:
        all_rows = []

    HEADERS_DISPATCH = ["ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸", "íƒë°°ì‚¬", "ì†¡ì¥ë²ˆí˜¸", "ì²˜ë¦¬ê²°ê³¼", "ìƒí’ˆëª…", "ìˆ˜ì·¨ì¸"]

    if not all_rows:
        all_rows = [HEADERS_DISPATCH]
        ws.update(range_name="A1", values=[HEADERS_DISPATCH])
    elif all_rows[0] != HEADERS_DISPATCH:
        all_rows[0] = HEADERS_DISPATCH
        ws.update(range_name="A1", values=[HEADERS_DISPATCH])

    headers = all_rows[0]

    existing_map = {}
    for row in all_rows[1:]:
        if row and row[0]:
            pid = str(row[0]).strip().lstrip("'")
            existing_map[pid] = row

    removed_count, added_count = 0, 0

    existing_ids = list(existing_map.keys())
    if existing_ids:
        current_status_list = []
        get_details(token, existing_ids, current_status_list)

        for item in current_status_list:
            pid = str(item.get("productOrder", {}).get("productOrderId", "")).strip()
            status = item.get("productOrder", {}).get("productOrderStatus")
            place_status = item.get("productOrder", {}).get("placeOrderStatus")

            if not (status == "PAYED" and place_status in ("NOT_YET", "OK")):
                if pid in existing_map:
                    del existing_map[pid]
                    removed_count += 1

    for order in orders:
        p = order.get("productOrder", {})
        pid = str(p.get("productOrderId", "")).strip()
        status = p.get("productOrderStatus")
        place_status = p.get("placeOrderStatus")

        if status == "PAYED" and place_status in ("NOT_YET", "OK"):
            if pid not in existing_map:
                addr = p.get("shippingAddress", {}) or {}
                safe_pid = f"'{pid}"
                existing_map[pid] = [
                    safe_pid,
                    "",
                    "",
                    "",
                    p.get("productName", ""),
                    addr.get("name", ""),
                ]
                added_count += 1
        else:
            if pid in existing_map:
                del existing_map[pid]
                removed_count += 1

    final_rows = [headers] + list(existing_map.values())
    ws.clear()
    ws.update(range_name="A1", values=final_rows, value_input_option="USER_ENTERED")
    logger.info(
        f"    âœ¨ [ê²°ê³¼] ğŸ†• {added_count}ê±´ ì¶”ê°€ | ğŸ—‘ï¸ {removed_count}ê±´ ì‚­ì œ | ğŸ“¦ ëŒ€ê¸°: {len(final_rows)-1}ê±´"
    )


# ==========================================
# 6. ì›ê°€ ë¡œë“œ ë° ì‹ ê·œìƒí’ˆ ë“±ë¡
# ==========================================
def sync_and_load_costs(orders_list):
    logger.info("ğŸ’° [ì›ê°€] ë¡œë”© ë° ì‹ ê·œ ìƒí’ˆ í™•ì¸...")
    ws = get_or_create_worksheet(TAB_NAME_COST)
    if not ws:
        return {}
    existing_values = ws.get_all_values()
    existing_keys = set()
    cost_map = {}

    HEADERS_COST = ["ìƒí’ˆë²ˆí˜¸(í•„ìˆ˜)", "ìƒí’ˆëª…", "ì˜µì…˜ëª…(ì¤‘ìš”)", "ì›ê°€(ë‹¨ê°€)"]
    if not existing_values:
        ws.update(range_name="A1", values=[HEADERS_COST])
        existing_values = [HEADERS_COST]
    elif existing_values[0] != HEADERS_COST:
        ws.update(range_name="A1", values=[HEADERS_COST])
        existing_values[0] = HEADERS_COST

    for row in existing_values[1:]:
        if len(row) >= 4 and row[0]:
            pid = str(row[0]).strip()
            opt = str(row[2]).strip()
            key_tuple = (pid, opt)
            existing_keys.add(key_tuple)

            cost_str = row[3].strip().replace(",", "")
            if cost_str.isdigit():
                cost_val = int(cost_str)
                cost_map[f"{pid}_{opt}"] = cost_val
                cost_map[f"{pid}_{opt.replace(' ', '')}"] = cost_val

    new_rows = []
    for order in orders_list:
        p = order.get("productOrder", {})
        pid = get_safe_product_id(p)
        pname = p.get("productName", "")
        poption = (p.get("productOption", "") or "").strip() or "-"

        if pid and pid != "None":
            key_tuple = (pid, poption)
            if key_tuple not in existing_keys:
                new_rows.append([pid, pname, poption, ""])
                existing_keys.add(key_tuple)

    if new_rows:
        ws.append_rows(new_rows, value_input_option="USER_ENTERED")
    return cost_map


# ==========================================
# 7. ì¥ë¶€ ì—…ë°ì´íŠ¸ (ìˆ˜ì • ë²„ì „)
# ==========================================
def update_archives(orders, cost_map, review_db):
    orders_by_month = {}
    for order_data in orders:
        o = order_data.get("order", {})
        payment_date = o.get("paymentDate", "")
        if payment_date:
            month_key = payment_date[:7]
            if month_key not in orders_by_month:
                orders_by_month[month_key] = []
            orders_by_month[month_key].append(order_data)

    HEADERS_ORDER = [
        "ì£¼ë¬¸ë²ˆí˜¸", "ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸", "ìƒí’ˆë²ˆí˜¸", "ì˜µì…˜ID", "ì£¼ë¬¸ìƒíƒœ",
        "í´ë ˆì„ìœ í˜•", "í´ë ˆì„ìƒíƒœ", "ê²°ì œì¼ì‹œ", "ìƒí’ˆëª…", "ì˜µì…˜ì •ë³´",
        "ìˆ˜ëŸ‰", "ì •ê°€", "ìƒí’ˆí• ì¸ê¸ˆì•¡", "ì´ê²°ì œê¸ˆì•¡", "ë°°ì†¡ë¹„",
        "ì£¼ë¬¸ìëª…", "ì£¼ë¬¸ìì—°ë½ì²˜", "ìˆ˜ì·¨ì¸ëª…", "ìˆ˜ì·¨ì¸ì—°ë½ì²˜", "ì£¼ì†Œ",
        "ë°°ì†¡ë©”ì„¸ì§€", "íƒë°°ì‚¬", "ì†¡ì¥ë²ˆí˜¸", "ë°œì†¡ê¸°í•œ", "ë°°ì†¡ì¡°íšŒ",
        "ìˆ˜ì§‘ì¼ì‹œ", "ë¦¬ë·°ìœ í˜•",
    ]
    
    HEADERS_SETTLE = [
        "ì£¼ë¬¸ë²ˆí˜¸", "ìƒí’ˆë²ˆí˜¸", "ì˜µì…˜ID", "ìƒí’ˆëª…", "ì˜µì…˜ì •ë³´",
        "ê²°ì œì¼ì‹œ", "êµ¬ë§¤í™•ì •ì¼", "ê²°ì œìˆ˜ë‹¨", "ìˆ˜ëŸ‰", "ì‹¤ê±°ë˜ë‹¨ê°€",
        "ì´ê²°ì œê¸ˆì•¡", "ìˆ˜ìˆ˜ë£Œ", "ë§¤ì…ì›ê°€(ì´)", "ë§ˆì§„", "ë§ˆì§„ìœ¨(%)",
        "ìœ ì…ê²½ë¡œ",
    ]

    for month, monthly_orders in orders_by_month.items():
        logger.info(f"ğŸ‘‰ [ì¥ë¶€ì—…ë°ì´íŠ¸] {month}ì›” ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        ws_order = get_or_create_worksheet(f"{PREFIX}_{month}")
        if ws_order:
            perform_upsert(ws_order, monthly_orders, HEADERS_ORDER, "order", cost_map, review_db)
        ws_settle = get_or_create_worksheet(f"{PREFIX}ì •ì‚°_{month}")
        if ws_settle:
            perform_upsert(ws_settle, monthly_orders, HEADERS_SETTLE, "settle", cost_map, review_db)


def perform_upsert(ws, new_orders_data, headers, mode, cost_map, review_db):
    try:
        all_values = ws.get_all_values()
    except:
        all_values = []

    now_str = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
    is_modified = False

    if not all_values:
        all_values = [headers]
        is_modified = True
    elif all_values[0] != headers:
        all_values[0] = headers
        is_modified = True

    id_map = {}
    for idx, row in enumerate(all_values):
        if idx != 0 and row:
            if mode == "order":
                if len(row) > 1:
                    key = str(row[1]).strip()
                    id_map[key] = idx
            else:
                if len(row) > 2:
                    order_id = str(row[0]).strip().lstrip("'")
                    prod_id = str(row[1]).strip()
                    option_id = str(row[2]).strip().lstrip("'")
                    key = f"{order_id}_{prod_id}_{option_id}"
                    id_map[key] = idx

    new_cnt, mod_cnt = 0, 0
    EXCLUDE_KEYWORDS = ["ì·¨ì†Œ", "ë°˜í’ˆ", "ê±°ë¶€", "CANCEL", "RETURN", "REJECT"]
    
    # ğŸ†• ì‚­ì œí•  ì¸ë±ìŠ¤ ìˆ˜ì§‘
    indices_to_delete = []

    for order_data in new_orders_data:
        p = order_data.get("productOrder", {})
        o = order_data.get("order", {})
        d = order_data.get("delivery", {})
        addr = p.get("shippingAddress", {})
        pid = str(p.get("productOrderId", "")).strip()
        prod_id = get_safe_product_id(p)
        if not pid:
            continue

        status_kr = translate_status(p.get("productOrderStatus"))
        claim_type_kr = translate_status(p.get("claimType"))
        claim_status_kr = translate_status(p.get("claimStatus"))
        
        if status_kr == "êµ¬ë§¤í™•ì •" and claim_type_kr == "ë°˜í’ˆ":
            claim_type_kr = "ë°˜í’ˆì² íšŒ"
        if status_kr == "êµ¬ë§¤í™•ì •" and claim_type_kr == "êµí™˜":
            claim_type_kr = "êµí™˜ì² íšŒ"
        if status_kr in ["ê²°ì œì™„ë£Œ", "ë°°ì†¡ì¤‘", "ë°°ì†¡ì™„ë£Œ"] and claim_type_kr == "ì·¨ì†Œ":
            claim_type_kr = "ì·¨ì†Œì² íšŒ"
        
        full_status = f"{p.get('productOrderStatus')} {p.get('claimType')}".upper()

        if mode == "settle":
            order_id = o.get("orderId", "")
            option_id = p.get("optionCode", "")
            delete_key = f"{order_id}_{prod_id}_{option_id}"
            
            # ğŸ†• ì‚­ì œ ëŒ€ìƒì¸ ê²½ìš° ì¸ë±ìŠ¤ë§Œ ìˆ˜ì§‘
            if any(bad in full_status for bad in EXCLUDE_KEYWORDS):
                if delete_key in id_map:
                    indices_to_delete.append(id_map[delete_key])
                continue

        raw_option = (p.get("productOption", "") or "").strip() or "-"

        unit_cost = cost_map.get(f"{prod_id}_{raw_option}", 0)
        if unit_cost == 0:
            unit_cost = cost_map.get(f"{prod_id}_{raw_option.replace(' ', '')}", 0)
        if unit_cost == 0:
            unit_cost = cost_map.get(f"{prod_id}_-", 0)

        pay_date = (
            o.get("paymentDate", "").split(".")[0].replace("T", " ")
            if o.get("paymentDate")
            else ""
        )
        row_data = []

        if mode == "order":
            courier = translate_courier(d.get("deliveryCompany", ""))
            t_no = d.get("trackingNumber", "")
            t_url = get_tracking_url(courier, t_no)

            o_name = o.get("ordererName", "")
            o_phone = (
                o.get("ordererTel1")
                or o.get("ordererTel2")
                or o.get("ordererTel")
                or ""
            )

            order_pid_str = str(pid).strip().replace("'", "")
            review_type_val = ""
            if order_pid_str in review_db:
                labels = sorted(list(review_db[order_pid_str]))
                review_type_val = " + ".join(labels)

            option_id = p.get("optionCode", "")

            row_data = [
                o.get("orderId"), pid, prod_id, f"'{option_id}",
                status_kr, claim_type_kr, claim_status_kr, pay_date,
                p.get("productName"), raw_option, p.get("quantity"),
                fmt(p.get("unitPrice", 0)),
                fmt(p.get("productDiscountAmount", 0)),
                fmt(p.get("totalPaymentAmount", 0)),
                fmt(p.get("deliveryFeeAmount", 0)),
                o_name, o_phone, addr.get("name"), addr.get("tel1"),
                f"{addr.get('baseAddress', '')} {addr.get('detailedAddress', '')}".strip(),
                p.get("shippingMemo"), courier, t_no,
                p.get("shippingDueDate", "")[:10], t_url, now_str,
                review_type_val,
            ]
        else:
            qty = p.get("quantity", 1)
            pay = p.get("totalPaymentAmount", 0)
            settle = p.get("expectedSettlementAmount", 0)
            
            fee = abs(pay - settle)
            total_cost = unit_cost * qty
            margin = settle - total_cost
            rate = f"{round((margin / pay) * 100, 1)}%" if pay > 0 else "0%"
            
            decision_date = (
                p.get("decisionDate", "").split(".")[0].replace("T", " ")
                if p.get("decisionDate")
                else "ë¯¸í™•ì •"
            )
            
            unit_real_price = int(pay / qty) if qty > 0 else 0
            option_id = p.get("optionCode", "")
            
            inflow_path = (
                p.get("inflowPath")
                or o.get("inflowPath")
                or order_data.get("inflowPath")
                or ""
            )
            inflow_path_add = (
                p.get("inflowPathAdd")
                or o.get("inflowPathAdd")
                or order_data.get("inflowPathAdd")
                or ""
            )
            inflow_display = translate_inflow_path(inflow_path, inflow_path_add)
            
            row_data = [
                o.get("orderId"), prod_id, f"'{option_id}",
                p.get("productName"), raw_option, pay_date,
                decision_date, o.get("paymentMeans"), qty,
                fmt(unit_real_price), fmt(pay), fmt(fee),
                fmt(total_cost), fmt(margin), rate,
                inflow_display,
            ]

        row_data = [str(x) for x in row_data]
        
        if mode == "order":
            key = pid
        else:
            order_id = o.get("orderId", "")
            option_id = p.get("optionCode", "")
            key = f"{order_id}_{prod_id}_{option_id}"
        
        if key in id_map:
            all_values[id_map[key]] = row_data
            mod_cnt += 1
        else:
            all_values.append(row_data)
            id_map[key] = len(all_values) - 1
            new_cnt += 1
        is_modified = True

    # ğŸ†• ì—­ìˆœìœ¼ë¡œ ì‚­ì œ (ì¸ë±ìŠ¤ í‹€ì–´ì§ ë°©ì§€)
    if indices_to_delete:
        for idx in sorted(set(indices_to_delete), reverse=True):
            if idx < len(all_values):
                del all_values[idx]
        is_modified = True
        logger.info(f"    ğŸ—‘ï¸ [{mode}] {len(set(indices_to_delete))}ê±´ ì‚­ì œ")

    if is_modified:
        header = all_values[0]
        data_rows = all_values[1:]
        
        try:
            if mode == "order":
                data_rows.sort(key=lambda x: x[7] if len(x) > 7 else "", reverse=True)
            else:
                data_rows.sort(key=lambda x: x[5] if len(x) > 5 else "", reverse=True)
        except:
            pass
        
        ws.clear()
        ws.update(
            range_name="A1",
            values=[header] + data_rows,
            value_input_option="USER_ENTERED",
        )
        
        if mode == "settle":
            logger.info(f"    ğŸ’¾ [ì •ì‚°] ì‹ ê·œ: {new_cnt} | ìˆ˜ì •: {mod_cnt}")
        else:
            logger.info(f"    ğŸ’¾ [ì£¼ë¬¸] ì‹ ê·œ: {new_cnt} | ìˆ˜ì •: {mod_cnt}")


# ==========================================
# 8. ë¦¬ë·° ì •ë°€ë¶„ì„ ë™ê¸°í™”
# ==========================================
def sync_review_to_all_sheets(review_db):
    logger.info("ğŸ”„ [ë¦¬ë·°ë™ê¸°í™”] ëª¨ë“  ì›”ë³„ ì‹œíŠ¸ì˜ ë¦¬ë·°ìœ í˜• ì»¬ëŸ¼ ë™ê¸°í™” ì¤‘...")

    now = datetime.now(KST)
    current_year = now.year

    target_months = [f"{current_year}-{m:02d}" for m in range(1, 13)]
    updated_sheets = 0

    for month in target_months:
        sheet_name = f"{PREFIX}_{month}"
        try:
            ws = get_or_create_worksheet(sheet_name)
            if not ws:
                continue

            all_values = ws.get_all_values()
            if not all_values or len(all_values) < 2:
                continue

            header = all_values[0]
            while len(header) <= TARGET_COL_INDEX:
                header.append("")
            header[TARGET_COL_INDEX] = TARGET_HEADER_NAME

            update_cnt = 0
            for idx, row in enumerate(all_values[1:], start=1):
                while len(row) <= TARGET_COL_INDEX:
                    row.append("")

                if len(row) > 0:
                    order_id = clean_order_id(row[0])
                else:
                    order_id = ""

                final_label = ""
                if order_id and order_id in review_db:
                    labels = sorted(list(review_db[order_id]))
                    final_label = " + ".join(labels)

                if row[TARGET_COL_INDEX] != final_label:
                    row[TARGET_COL_INDEX] = final_label
                    update_cnt += 1

                all_values[idx] = row

            if update_cnt > 0:
                ws.clear()
                ws.update(
                    range_name="A1",
                    values=all_values,
                    value_input_option="USER_ENTERED",
                )
                logger.info(f"    âœ… [{sheet_name}] {update_cnt}ê±´ ì—…ë°ì´íŠ¸")
                updated_sheets += 1
                time.sleep(1)

        except Exception as e:
            logger.warning(f"    âš ï¸  [{sheet_name}] ì‹¤íŒ¨: {e}")
            continue

    logger.info(f"   ğŸ‰ ì´ {updated_sheets}ê°œ ì‹œíŠ¸ ë™ê¸°í™” ì™„ë£Œ")


# ==========================================
# 9. í†µê³„ ì‹œíŠ¸ ìë™ ìƒì„±
# ==========================================
def generate_statistics_sheet():
    logger.info("\nğŸ“Š [í†µê³„ì‹œíŠ¸] ìƒì„± ì¤‘...")

    ws = get_or_create_worksheet(TAB_NAME_STATS)
    if not ws:
        logger.error("   âŒ í†µê³„ ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨")
        return

    existing_data = {}
    try:
        saved_values = ws.get("A2:J100", value_render_option="UNFORMATTED_VALUE")
        for idx, row in enumerate(saved_values):
            row_num = idx + 2
            if len(row) > 6:
                existing_data[row_num] = {
                    "G": row[6] if len(row) > 6 else "",
                    "H": row[7] if len(row) > 7 else "",
                }
        logger.info(f"   ğŸ’¾ ê¸°ì¡´ ê´‘ê³ ë¹„/í˜œíƒë¹„ ë°ì´í„° ë³´ì¡´: {len(existing_data)}í–‰")
    except Exception:
        logger.info("   â„¹ï¸  ê¸°ì¡´ ë°ì´í„° ì—†ìŒ")

    headers = [
        "ì›”", "1.ì´ ë§¤ì¶œì•¡", "2.ì´ ë§ˆì§„ì•¡", "3.í‰ê·  ë§ˆì§„ìœ¨", "4.ê°€ì¤‘ í‰ê·  ë§ˆì§„ìœ¨",
        "5.ì´ ì£¼ë¬¸ ìˆ˜", "6.ë„¤ì´ë²„ ê´‘ê³ ë¹„", "7.í˜œíƒ ì •ì‚°ë¹„", "8.ì‹¤ì§ˆ ì´ ë§ˆì§„ì•¡",
        "9.ì‹¤ì§ˆ ê°€ì¤‘ ë§ˆì§„ìœ¨", "10.ì‹ ìš©ì¹´ë“œ%", "11.ê°„í¸ê²°ì œ%", "12.ê³„ì¢Œì´ì²´%",
        "13.ë¬´í†µì¥%", "14.í¬ì¸íŠ¸/ë¨¸ë‹ˆ%",
    ]

    rows = [headers]

    now = datetime.now(KST)
    current_year = now.year

    for m in range(1, 13):
        month_key = f"{current_year}-{m:02d}"
        sheet_ref = f"'{PREFIX}ì •ì‚°_{month_key}'!"
        row_num = m + 1

        saved_g = existing_data.get(row_num, {}).get("G", "")
        saved_h = existing_data.get(row_num, {}).get("H", "")

        row = [
            f"{m}ì›”",
            f"=IFERROR(SUM({sheet_ref}K:K),0)",
            f"=IFERROR(SUM({sheet_ref}N:N),0)",
            f"=IFERROR(AVERAGE({sheet_ref}O:O),0)",
            f"=IFERROR(IF(B{row_num}=0,0,C{row_num}/B{row_num}),0)",
            f"=IFERROR(COUNTA({sheet_ref}A2:A),0)",
            saved_g,
            saved_h,
            f"=IFERROR(IF(OR(ISBLANK(G{row_num}),ISBLANK(H{row_num})),C{row_num},C{row_num}-VALUE(G{row_num})-VALUE(H{row_num})),C{row_num})",
            f"=IFERROR(IF(B{row_num}=0,0,I{row_num}/B{row_num}),0)",
            f"=IFERROR(COUNTIFS({sheet_ref}H:H,\"*ì‹ ìš©ì¹´ë“œ*\")/COUNTA({sheet_ref}H2:H),0)",
            f"=IFERROR(COUNTIFS({sheet_ref}H:H,\"*ê°„í¸*\")/COUNTA({sheet_ref}H2:H),0)",
            f"=IFERROR(COUNTIFS({sheet_ref}H:H,\"*ê³„ì¢Œ*\")/COUNTA({sheet_ref}H2:H),0)",
            f"=IFERROR(COUNTIFS({sheet_ref}H:H,\"*ë¬´í†µì¥*\")/COUNTA({sheet_ref}H2:H),0)",
            f"=IFERROR((COUNTIFS({sheet_ref}H:H,\"*í¬ì¸íŠ¸*\")+COUNTIFS({sheet_ref}H:H,\"*ë¨¸ë‹ˆ*\"))/COUNTA({sheet_ref}H2:H),0)",
        ]
        rows.append(row)

    rows.append([""] * len(headers))
    total_row_index = len(rows) + 1

    saved_g_total = existing_data.get(total_row_index, {}).get("G", "")
    saved_h_total = existing_data.get(total_row_index, {}).get("H", "")

    total_row = [
        f"ğŸ”¥ {current_year} ëˆ„ì  í•©ê³„",
        "=SUM(B2:B13)", "=SUM(C2:C13)", "=AVERAGE(D2:D13)",
        f"=IFERROR(IF(B{total_row_index}=0,0,C{total_row_index}/B{total_row_index}),0)",
        "=SUM(F2:F13)",
        "=SUM(G2:G13)" if not saved_g_total else saved_g_total,
        "=SUM(H2:H13)" if not saved_h_total else saved_h_total,
        "=SUM(I2:I13)",
        f"=IFERROR(IF(B{total_row_index}=0,0,I{total_row_index}/B{total_row_index}),0)",
    ]
    rows.append(total_row)

    try:
        ws.clear()
        ws.update(range_name="A1", values=rows, value_input_option="USER_ENTERED")

        fmt_currency = {"numberFormat": {"type": "NUMBER", "pattern": "#,##0"}}
        fmt_percent = {"numberFormat": {"type": "PERCENT", "pattern": "0.00%"}}

        ws.format("B2:C", fmt_currency)
        ws.format("D2:E", fmt_percent)
        ws.format("F2:F", fmt_currency)
        ws.format("G2:I", fmt_currency)
        ws.format("J2:J", fmt_percent)
        ws.format("K2:O", fmt_percent)

        ws.format("A1:O1", {
            "backgroundColor": {"red": 0.2, "green": 0.5, "blue": 0.8},
            "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}},
        })

        ws.format(f"A{total_row_index}:O{total_row_index}", {
            "backgroundColor": {"red": 1, "green": 0.9, "blue": 0.7},
            "textFormat": {"bold": True},
        })

        ws.format("G2:H13", {
            "backgroundColor": {"red": 1, "green": 1, "blue": 0.8},
        })

        logger.info("   âœ… í†µê³„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ!")
    except Exception as e:
        logger.error(f"   âŒ í†µê³„ ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")


# ==========================================
# 10. Në°°ì†¡ ë§ˆìŠ¤í„° ì‹œíŠ¸ ë¡œë“œ
# ==========================================
def load_ndelivery_master():
    logger.info("ğŸ“‹ [Në°°ì†¡ë§ˆìŠ¤í„°] ì‹œíŠ¸ ë¡œë“œ ì¤‘...")
    
    ws = get_or_create_worksheet(TAB_NAME_NDELIVERY_MASTER)
    if not ws:
        logger.error("   âŒ Në°°ì†¡ë§ˆìŠ¤í„° ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    try:
        all_values = ws.get_all_values()
        if len(all_values) <= 1:
            logger.warning("   âš ï¸ Në°°ì†¡ë§ˆìŠ¤í„° ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        ndelivery_products = {}
        for row in all_values[1:]:
            if len(row) >= 1 and row[0]:
                option_id = str(row[0]).strip().replace("'", "")
                option_id2 = str(row[1]).strip().replace("'", "") if len(row) > 1 else ""
                name = str(row[2]).strip() if len(row) > 2 else ""
                
                if option_id:
                    ndelivery_products[option_id] = (name, option_id2)
        
        logger.info(f"   âœ… {len(ndelivery_products)}ê°œ Në°°ì†¡ ìƒí’ˆ ë¡œë“œ ì™„ë£Œ")
        return ndelivery_products
        
    except Exception as e:
        logger.error(f"   âŒ Në°°ì†¡ë§ˆìŠ¤í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


# ==========================================
# 11. Në°°ì†¡ í˜„í™© ëŒ€ì‹œë³´ë“œ ìƒì„±
# ==========================================
def generate_ndelivery_status_for_month(year, month, ndelivery_products):
    if not ndelivery_products:
        return
    
    month_str = f"{year}-{month:02d}"
    sheet_name = f"{PREFIX}_{month_str}"
    status_sheet_name = f"{PREFIX}_Në°°ì†¡í˜„í™©_{month:02d}ì›”"
    
    logger.info(f"\nğŸ“¦ [Në°°ì†¡í˜„í™©] {month}ì›” ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
    
    ws_order = get_or_create_worksheet(sheet_name)
    if not ws_order:
        logger.warning(f"   âš ï¸ {sheet_name} ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        all_orders = ws_order.get_all_values()
        if len(all_orders) <= 1:
            logger.warning(f"   âš ï¸ {sheet_name} ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
    except Exception as e:
        logger.error(f"   âŒ ì£¼ë¬¸ ì‹œíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    COL_OPTION_ID = 3
    COL_ORDER_STATUS = 4
    COL_CLAIM_TYPE = 5
    COL_CLAIM_STATUS = 6
    COL_QTY = 10
    
    option_id_map = {}
    for opt_id, (name, opt_id2) in ndelivery_products.items():
        option_id_map[opt_id] = opt_id
        if opt_id2:
            option_id_map[opt_id2] = opt_id
    
    product_stats = {}
    for opt_id in ndelivery_products.keys():
        product_stats[opt_id] = {
            'êµ¬ë§¤í™•ì •': 0, 'êµí™˜ì™„ë£Œ': 0, 'ë°˜í’ˆì™„ë£Œ': 0,
            'ë°˜í’ˆìš”ì²­': 0, 'ë°˜í’ˆìˆ˜ê±°ì¤‘': 0, 'ë°˜í’ˆìˆ˜ê±°ì™„ë£Œ': 0,
            'ê²°ì œì™„ë£Œ': 0, 'ë°°ì†¡ì¤‘': 0, 'ë°°ì†¡ì™„ë£Œ': 0, 'ì·¨ì†Œì™„ë£Œ': 0,
        }
    
    for row in all_orders[1:]:
        if len(row) <= COL_QTY:
            continue
        
        option_id = str(row[COL_OPTION_ID]).strip().replace("'", "")
        order_status = str(row[COL_ORDER_STATUS]).strip()
        claim_type = str(row[COL_CLAIM_TYPE]).strip()
        claim_status = str(row[COL_CLAIM_STATUS]).strip()
        
        try:
            qty = int(row[COL_QTY]) if row[COL_QTY] else 1
        except:
            qty = 1
        
        if option_id not in option_id_map:
            continue
        
        main_option_id = option_id_map[option_id]
        
        if order_status == 'êµ¬ë§¤í™•ì •':
            product_stats[main_option_id]['êµ¬ë§¤í™•ì •'] += qty
        elif order_status == 'êµí™˜ì™„ë£Œ':
            product_stats[main_option_id]['êµí™˜ì™„ë£Œ'] += qty
        elif order_status == 'ë°˜í’ˆì™„ë£Œ':
            product_stats[main_option_id]['ë°˜í’ˆì™„ë£Œ'] += qty
        elif order_status == 'ì·¨ì†Œì™„ë£Œ':
            product_stats[main_option_id]['ì·¨ì†Œì™„ë£Œ'] += qty
        elif order_status == 'ê²°ì œì™„ë£Œ' and claim_type == '':
            product_stats[main_option_id]['ê²°ì œì™„ë£Œ'] += qty
        elif order_status == 'ë°°ì†¡ì¤‘' and claim_type == '':
            product_stats[main_option_id]['ë°°ì†¡ì¤‘'] += qty
        elif order_status == 'ë°°ì†¡ì™„ë£Œ' and claim_type == '':
            product_stats[main_option_id]['ë°°ì†¡ì™„ë£Œ'] += qty
        
        if claim_type == 'ë°˜í’ˆ':
            if claim_status == 'ë°˜í’ˆìš”ì²­':
                product_stats[main_option_id]['ë°˜í’ˆìš”ì²­'] += qty
            elif claim_status == 'ìˆ˜ê±°ì¤‘':
                product_stats[main_option_id]['ë°˜í’ˆìˆ˜ê±°ì¤‘'] += qty
            elif claim_status == 'ìˆ˜ê±°ì™„ë£Œ':
                product_stats[main_option_id]['ë°˜í’ˆìˆ˜ê±°ì™„ë£Œ'] += qty
    
    ws_status = get_or_create_worksheet(status_sheet_name)
    if not ws_status:
        logger.error(f"   âŒ {status_sheet_name} ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨")
        return
    
    headers = [
        "ì˜µì…˜ID", "ì˜µì…˜ID2", "ìƒí’ˆëª…", "ì´ ì°¨ê° ì¬ê³ ",
        "êµ¬ë§¤í™•ì •", "êµí™˜ì™„ë£Œ", "ë°˜í’ˆì™„ë£Œ", "ë°˜í’ˆìš”ì²­",
        "ë°˜í’ˆìˆ˜ê±°ì¤‘", "ë°˜í’ˆìˆ˜ê±°ì™„ë£Œ", "ê²°ì œì™„ë£Œ", "ë°°ì†¡ì¤‘",
        "ë°°ì†¡ì™„ë£Œ", "ì·¨ì†Œì™„ë£Œ",
    ]
    
    rows = [headers]
    
    for opt_id, (name, opt_id2) in ndelivery_products.items():
        stats = product_stats[opt_id]
        total_deduct = stats['êµ¬ë§¤í™•ì •'] + stats['êµí™˜ì™„ë£Œ'] - stats['ë°˜í’ˆì™„ë£Œ']
        
        row = [
            f"'{opt_id}", f"'{opt_id2}" if opt_id2 else "", name, total_deduct,
            stats['êµ¬ë§¤í™•ì •'], stats['êµí™˜ì™„ë£Œ'], stats['ë°˜í’ˆì™„ë£Œ'], stats['ë°˜í’ˆìš”ì²­'],
            stats['ë°˜í’ˆìˆ˜ê±°ì¤‘'], stats['ë°˜í’ˆìˆ˜ê±°ì™„ë£Œ'], stats['ê²°ì œì™„ë£Œ'], stats['ë°°ì†¡ì¤‘'],
            stats['ë°°ì†¡ì™„ë£Œ'], stats['ì·¨ì†Œì™„ë£Œ'],
        ]
        rows.append(row)
    
    data_rows = rows[1:]
    data_rows.sort(key=lambda x: x[3] if isinstance(x[3], int) else 0, reverse=True)
    rows = [headers] + data_rows
    
    total_row = [
        "", "", "ğŸ”¥ í•©ê³„",
        sum(r[3] for r in data_rows if isinstance(r[3], int)),
        sum(r[4] for r in data_rows if isinstance(r[4], int)),
        sum(r[5] for r in data_rows if isinstance(r[5], int)),
        sum(r[6] for r in data_rows if isinstance(r[6], int)),
        sum(r[7] for r in data_rows if isinstance(r[7], int)),
        sum(r[8] for r in data_rows if isinstance(r[8], int)),
        sum(r[9] for r in data_rows if isinstance(r[9], int)),
        sum(r[10] for r in data_rows if isinstance(r[10], int)),
        sum(r[11] for r in data_rows if isinstance(r[11], int)),
        sum(r[12] for r in data_rows if isinstance(r[12], int)),
        sum(r[13] for r in data_rows if isinstance(r[13], int)),
    ]
    rows.append(total_row)
    
    try:
        ws_status.clear()
        ws_status.update(range_name="A1", values=rows, value_input_option="USER_ENTERED")
        
        update_time = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
        ws_status.update(range_name="P1", values=[[f"ìµœì¢… ì—…ë°ì´íŠ¸: {update_time}"]])
        
        logger.info(f"   âœ… {status_sheet_name} ìƒì„± ì™„ë£Œ!")
        logger.info(f"      ì´ ì°¨ê°: {total_row[3]} | êµ¬ë§¤í™•ì •: {total_row[4]} | êµí™˜: {total_row[5]} | ë°˜í’ˆ: {total_row[6]}")
        
    except Exception as e:
        logger.error(f"   âŒ {status_sheet_name} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


def generate_ndelivery_status_dashboard():
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“¦ [Në°°ì†¡í˜„í™©] ì›”ë³„ ëŒ€ì‹œë³´ë“œ ìƒì„±")
    logger.info("=" * 50)
    
    ndelivery_products = load_ndelivery_master()
    if not ndelivery_products:
        logger.warning("   âš ï¸ Në°°ì†¡ë§ˆìŠ¤í„° ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ì–´ ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    now = datetime.now(KST)
    current_year = now.year
    current_month = now.month
    
    if current_month == 1:
        prev_year = current_year - 1
        prev_month = 12
    else:
        prev_year = current_year
        prev_month = current_month - 1
    
    generate_ndelivery_status_for_month(prev_year, prev_month, ndelivery_products)
    time.sleep(1)
    generate_ndelivery_status_for_month(current_year, current_month, ndelivery_products)
    
    logger.info("\n   ğŸ‰ Në°°ì†¡í˜„í™© ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ!")


# ==========================================
# 12. ë©”ì¸ ì‹¤í–‰
# ==========================================
if __name__ == "__main__":
    logger.info("\n" + "=" * 70)
    logger.info(f"ğŸ¤– Optimus Daily + Review + Stats + Në°°ì†¡ ({PREFIX})")
    logger.info("   âœ… Gì—´: í´ë ˆì„ìƒíƒœ ì¶”ê°€")
    logger.info("   âœ… Fì—´: í´ë ˆì„ìœ í˜•")
    logger.info("   âœ… ë°˜í’ˆ/êµí™˜/ì·¨ì†Œ ì² íšŒ ìë™ ê°ì§€")
    logger.info("   âœ… Në°°ì†¡ í˜„í™© ëŒ€ì‹œë³´ë“œ")
    logger.info("   âœ… IndexError ìˆ˜ì • ì™„ë£Œ ğŸ”¥")
    logger.info("=" * 70)

    token = get_naver_token()
    if token:
        try:
            review_db = load_review_database_advanced()
            dispatch = fetch_target_orders_for_dispatch(token)
            auto_fill_dispatch_sheet(token, dispatch)
            archive = fetch_recent_changes_for_archive(token)
            all_data = dispatch + archive
            cost_map = sync_and_load_costs(all_data)
            
            if archive:
                update_archives(archive, cost_map, review_db)
            
            if review_db:
                sync_review_to_all_sheets(review_db)
            
            generate_statistics_sheet()
            generate_ndelivery_status_dashboard()

            logger.info("\n" + "=" * 70)
            logger.info("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("=" * 70)

        except KeyboardInterrupt:
            logger.info("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            logger.error(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
    else:
        logger.error("âŒ í† í° ë°œê¸‰ ì‹¤íŒ¨ë¡œ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
